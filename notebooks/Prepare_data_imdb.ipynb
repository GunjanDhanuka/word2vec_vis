{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7b4bd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  # For preprocessing\n",
    "import pandas as pd  # For data handling\n",
    "from time import time  # To time our operations\n",
    "from collections import defaultdict  # For word frequency\n",
    "from tqdm.notebook import tqdm\n",
    "import spacy  # For preprocessing\n",
    "import nltk\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import WordNetLemmatizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1efb5c8-2c0c-4cc4-8b34-13100a853376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/gunjan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/gunjan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/gunjan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48a4a967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a96023e0-1bd0-4c09-8fd5-c5fc55d10da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37cdafed-6d65-4242-99bc-c7f07c699c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b30edc13-1305-426a-afdc-34d57b3d8985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna().reset_index(drop=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd1454bd-d85a-4f80-b1a1-cf2c33e4e173",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_COL = 'review'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be0119e-77db-4158-a4e4-4a71582478d4",
   "metadata": {},
   "source": [
    "## Cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7bc77f0b-e0e6-493f-8679-6cc1ba028710",
   "metadata": {},
   "outputs": [],
   "source": [
    "Word = WordNetLemmatizer()\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3a53992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(raw):\n",
    "    result = re.sub(\"<[a][^>]*>(.+?)</[a]>\", 'Link.', raw)\n",
    "    result = re.sub('&gt;', \"\", result) # greater than sign\n",
    "    result = re.sub('&#x27;', \"'\", result) # apostrophe\n",
    "    # result = re.sub('&quot;', '\"', result) \n",
    "    result = re.sub('&#x2F;', ' ', result)\n",
    "    result = re.sub('<p>', ' ', result) # paragraph tag\n",
    "    result = re.sub('<i>', ' ', result) #italics tag\n",
    "    result = re.sub('</i>', '', result) \n",
    "    result = re.sub('&#62;', '', result)\n",
    "    result = re.sub(\"\\n\", '', result) # newline \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab17b919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    text = re.sub(r\"[^a-zA-Z0-9?!.,]+\", ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a5f1fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case(df):\n",
    "    df[TEXT_COL] = df[TEXT_COL].apply(lambda x: \" \".join(x.lower() for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c099d82-85bd-4e16-8b21-66622db3f69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(df):\n",
    "    df[TEXT_COL] = df[TEXT_COL].apply(lambda x: \" \".join([Word.lemmatize(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "350ac42b-55e4-4028-9ce8-f8a655a49e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_words_remove(df):\n",
    "    df[TEXT_COL] = df[TEXT_COL].apply(lambda x: \" \".join(x for x in x.split() if x not in stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22baf874-6128-4999-ac5f-75a5a37473f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df[TEXT_COL] = df[TEXT_COL].apply(clean)\n",
    "    df[TEXT_COL] = df[TEXT_COL].apply(lambda x: remove_punct(x))\n",
    "    lower_case(df)\n",
    "    stop_words_remove(df)\n",
    "    lemmatize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dcf73202-a5e4-40a4-9bfe-7a8128d0587c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to clean up everything: 0.56 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "preprocess(df)\n",
    "\n",
    "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c968b0c-dc28-4b9e-b5a2-b18527157f56",
   "metadata": {},
   "source": [
    "## Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e59a6b0b-9fcf-4c57-a157-1eb270752bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b939a8d5-1009-4581-bea1-161ee70d8404",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [row.split() for row in df[TEXT_COL]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7630881b-3435-4d68-b7cb-434922e91a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11:26:30: collecting all words and their counts\n",
      "INFO - 11:26:30: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 11:26:31: PROGRESS: at sentence #5000, processed 608451 words and 481638 word types\n",
      "INFO - 11:26:31: PROGRESS: at sentence #10000, processed 1215835 words and 861349 word types\n",
      "INFO - 11:26:32: PROGRESS: at sentence #15000, processed 1827330 words and 1206409 word types\n",
      "INFO - 11:26:33: PROGRESS: at sentence #20000, processed 2431867 words and 1525124 word types\n",
      "INFO - 11:26:34: PROGRESS: at sentence #25000, processed 3043520 words and 1831358 word types\n",
      "INFO - 11:26:34: PROGRESS: at sentence #30000, processed 3646687 words and 2118658 word types\n",
      "INFO - 11:26:35: PROGRESS: at sentence #35000, processed 4256720 words and 2401073 word types\n",
      "INFO - 11:26:36: PROGRESS: at sentence #40000, processed 4859876 words and 2668485 word types\n",
      "INFO - 11:26:37: PROGRESS: at sentence #45000, processed 5477871 words and 2934388 word types\n",
      "INFO - 11:26:38: collected 3184082 token types (unigram + bigrams) from a corpus of 6079521 words and 50000 sentences\n",
      "INFO - 11:26:38: merged Phrases<3184082 vocab, min_count=20, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 11:26:38: Phrases lifecycle event {'msg': 'built Phrases<3184082 vocab, min_count=20, threshold=10.0, max_vocab_size=40000000> in 7.70s', 'datetime': '2022-06-25T11:26:38.080285', 'gensim': '4.2.0', 'python': '3.8.0 (default, Nov  6 2019, 21:49:08) \\n[GCC 7.3.0]', 'platform': 'Linux-5.13.0-51-generic-x86_64-with-glibc2.10', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# min_count (float, optional) – Ignore all words and bigrams with total collected count lower than this value.\n",
    "phrases = Phrases(sent, min_count=20, progress_per=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60f37690-8947-45ee-bec6-6e9ea9279ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11:26:51: exporting phrases from Phrases<3184082 vocab, min_count=20, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 11:26:57: FrozenPhrases lifecycle event {'msg': 'exported FrozenPhrases<4902 phrases, min_count=20, threshold=10.0> from Phrases<3184082 vocab, min_count=20, threshold=10.0, max_vocab_size=40000000> in 5.93s', 'datetime': '2022-06-25T11:26:57.843759', 'gensim': '4.2.0', 'python': '3.8.0 (default, Nov  6 2019, 21:49:08) \\n[GCC 7.3.0]', 'platform': 'Linux-5.13.0-51-generic-x86_64-with-glibc2.10', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d366405c-7db3-4307-8aaa-3b7cef2fc40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = bigram[sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04860170-3a26-4811-96ae-e5bd6cf94ece",
   "metadata": {},
   "source": [
    "### Most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b6d494a-fc29-4097-a27f-0b439cfdc4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168334"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = defaultdict(int)\n",
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09fd71e2-ca67-4c4a-b675-eab7668cd054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie',\n",
       " 'film',\n",
       " 'br',\n",
       " 'one',\n",
       " 'like',\n",
       " 'good',\n",
       " 'time',\n",
       " 'character',\n",
       " 'get',\n",
       " 'would']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53060dfb-1cb4-4cb8-847d-7030bc235a1f",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a20e82db-e608-41cf-be30-38ec9beabb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f9a7d2e-ec64-4e72-b288-7c360b7dd820",
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "78366fde-9983-4360-b7e4-b4b56e901004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11:30:13: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=300, alpha=0.03>', 'datetime': '2022-06-25T11:30:13.447139', 'gensim': '4.2.0', 'python': '3.8.0 (default, Nov  6 2019, 21:49:08) \\n[GCC 7.3.0]', 'platform': 'Linux-5.13.0-51-generic-x86_64-with-glibc2.10', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec(min_count=20,\n",
    "                     window=2,\n",
    "                     vector_size=300,\n",
    "                     sample=6e-5,\n",
    "                     sg=1,\n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=cores-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf8114ce-6a56-48a9-8e6e-2711407d0eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11:30:45: collecting all words and their counts\n",
      "INFO - 11:30:45: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 11:30:46: PROGRESS: at sentence #10000, processed 1140281 words, keeping 70769 word types\n",
      "INFO - 11:30:47: PROGRESS: at sentence #20000, processed 2280442 words, keeping 101555 word types\n",
      "INFO - 11:30:48: PROGRESS: at sentence #30000, processed 3419370 words, keeping 126312 word types\n",
      "INFO - 11:30:49: PROGRESS: at sentence #40000, processed 4557220 words, keeping 148615 word types\n",
      "INFO - 11:30:50: collected 168334 word types from a corpus of 5701144 raw words and 50000 sentences\n",
      "INFO - 11:30:50: Creating a fresh vocabulary\n",
      "INFO - 11:30:50: Word2Vec lifecycle event {'msg': 'effective_min_count=20 retains 21975 unique words (13.05% of original 168334, drops 146359)', 'datetime': '2022-06-25T11:30:50.710895', 'gensim': '4.2.0', 'python': '3.8.0 (default, Nov  6 2019, 21:49:08) \\n[GCC 7.3.0]', 'platform': 'Linux-5.13.0-51-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "INFO - 11:30:50: Word2Vec lifecycle event {'msg': 'effective_min_count=20 leaves 5315592 word corpus (93.24% of original 5701144, drops 385552)', 'datetime': '2022-06-25T11:30:50.711639', 'gensim': '4.2.0', 'python': '3.8.0 (default, Nov  6 2019, 21:49:08) \\n[GCC 7.3.0]', 'platform': 'Linux-5.13.0-51-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "INFO - 11:30:50: deleting the raw counts dictionary of 168334 items\n",
      "INFO - 11:30:50: sample=6e-05 downsamples 1036 most-common words\n",
      "INFO - 11:30:50: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 3340311.394779458 word corpus (62.8%% of prior 5315592)', 'datetime': '2022-06-25T11:30:50.815750', 'gensim': '4.2.0', 'python': '3.8.0 (default, Nov  6 2019, 21:49:08) \\n[GCC 7.3.0]', 'platform': 'Linux-5.13.0-51-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "INFO - 11:30:50: estimated required memory for 21975 words and 300 dimensions: 63727500 bytes\n",
      "INFO - 11:30:50: resetting layer weights\n",
      "INFO - 11:30:51: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-06-25T11:30:51.000027', 'gensim': '4.2.0', 'python': '3.8.0 (default, Nov  6 2019, 21:49:08) \\n[GCC 7.3.0]', 'platform': 'Linux-5.13.0-51-generic-x86_64-with-glibc2.10', 'event': 'build_vocab'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.08 mins\n"
     ]
    }
   ],
   "source": [
    "# Building vocabulary table\n",
    "t = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11ff646-31d9-4dd5-9aca-b8f40ac64eac",
   "metadata": {},
   "source": [
    "### Training of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c7423a5c-59db-4151-b05e-af006cd0d9df",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11:31:20: Word2Vec lifecycle event {'msg': 'training model with 11 workers on 21975 vocabulary and 300 features, using sg=1 hs=0 sample=6e-05 negative=20 window=2 shrink_windows=True', 'datetime': '2022-06-25T11:31:20.467640', 'gensim': '4.2.0', 'python': '3.8.0 (default, Nov  6 2019, 21:49:08) \\n[GCC 7.3.0]', 'platform': 'Linux-5.13.0-51-generic-x86_64-with-glibc2.10', 'event': 'train'}\n",
      "INFO - 11:31:21: EPOCH 0 - PROGRESS: at 4.96% examples, 161011 words/s, in_qsize 21, out_qsize 1\n",
      "INFO - 11:31:22: EPOCH 0 - PROGRESS: at 10.28% examples, 165291 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:31:23: EPOCH 0 - PROGRESS: at 16.30% examples, 176505 words/s, in_qsize 17, out_qsize 4\n",
      "INFO - 11:31:24: EPOCH 0 - PROGRESS: at 22.84% examples, 186091 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:31:25: EPOCH 0 - PROGRESS: at 29.01% examples, 185517 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:31:26: EPOCH 0 - PROGRESS: at 36.01% examples, 192490 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:31:27: EPOCH 0 - PROGRESS: at 42.75% examples, 197029 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:31:28: EPOCH 0 - PROGRESS: at 49.01% examples, 198339 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:31:29: EPOCH 0 - PROGRESS: at 54.98% examples, 197389 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:31:30: EPOCH 0 - PROGRESS: at 60.89% examples, 196829 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:31:31: EPOCH 0 - PROGRESS: at 67.50% examples, 198649 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:31:32: EPOCH 0 - PROGRESS: at 72.89% examples, 197040 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:31:33: EPOCH 0 - PROGRESS: at 78.85% examples, 197012 words/s, in_qsize 20, out_qsize 2\n",
      "INFO - 11:31:34: EPOCH 0 - PROGRESS: at 85.27% examples, 197942 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:31:35: EPOCH 0 - PROGRESS: at 92.29% examples, 200460 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:31:36: EPOCH 0: training on 5701144 raw words (3341304 effective words) took 16.4s, 203904 effective words/s\n",
      "INFO - 11:31:37: EPOCH 1 - PROGRESS: at 3.55% examples, 115203 words/s, in_qsize 17, out_qsize 6\n",
      "INFO - 11:31:38: EPOCH 1 - PROGRESS: at 10.26% examples, 169864 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:31:39: EPOCH 1 - PROGRESS: at 15.46% examples, 170041 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:31:40: EPOCH 1 - PROGRESS: at 22.01% examples, 182535 words/s, in_qsize 18, out_qsize 2\n",
      "INFO - 11:31:41: EPOCH 1 - PROGRESS: at 28.80% examples, 190586 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:31:42: EPOCH 1 - PROGRESS: at 35.08% examples, 192554 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:31:43: EPOCH 1 - PROGRESS: at 41.33% examples, 194617 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:31:44: EPOCH 1 - PROGRESS: at 47.60% examples, 196150 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:31:46: EPOCH 1 - PROGRESS: at 53.59% examples, 195909 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:31:47: EPOCH 1 - PROGRESS: at 60.39% examples, 198487 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:31:48: EPOCH 1 - PROGRESS: at 67.50% examples, 201874 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:31:49: EPOCH 1 - PROGRESS: at 73.22% examples, 200102 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:31:50: EPOCH 1 - PROGRESS: at 79.38% examples, 200209 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:31:51: EPOCH 1 - PROGRESS: at 86.29% examples, 202156 words/s, in_qsize 21, out_qsize 1\n",
      "INFO - 11:31:52: EPOCH 1 - PROGRESS: at 92.63% examples, 202999 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:31:53: EPOCH 1 - PROGRESS: at 100.00% examples, 205290 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 11:31:53: EPOCH 1: training on 5701144 raw words (3340285 effective words) took 16.3s, 205276 effective words/s\n",
      "INFO - 11:31:54: EPOCH 2 - PROGRESS: at 4.96% examples, 161531 words/s, in_qsize 18, out_qsize 0\n",
      "INFO - 11:31:55: EPOCH 2 - PROGRESS: at 11.25% examples, 186030 words/s, in_qsize 21, out_qsize 1\n",
      "INFO - 11:31:56: EPOCH 2 - PROGRESS: at 17.86% examples, 196189 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:31:57: EPOCH 2 - PROGRESS: at 24.06% examples, 198544 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:31:58: EPOCH 2 - PROGRESS: at 30.60% examples, 201559 words/s, in_qsize 18, out_qsize 0\n",
      "INFO - 11:31:59: EPOCH 2 - PROGRESS: at 36.18% examples, 197798 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:32:00: EPOCH 2 - PROGRESS: at 42.94% examples, 201035 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:32:01: EPOCH 2 - PROGRESS: at 48.84% examples, 200221 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:32:02: EPOCH 2 - PROGRESS: at 55.66% examples, 202588 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:32:03: EPOCH 2 - PROGRESS: at 62.80% examples, 205582 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:32:04: EPOCH 2 - PROGRESS: at 68.91% examples, 205269 words/s, in_qsize 17, out_qsize 5\n",
      "INFO - 11:32:05: EPOCH 2 - PROGRESS: at 75.65% examples, 206848 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:32:06: EPOCH 2 - PROGRESS: at 82.36% examples, 207768 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:32:07: EPOCH 2 - PROGRESS: at 88.82% examples, 208586 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:32:08: EPOCH 2 - PROGRESS: at 95.75% examples, 210121 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:32:08: EPOCH 2: training on 5701144 raw words (3340907 effective words) took 15.8s, 211744 effective words/s\n",
      "INFO - 11:32:09: EPOCH 3 - PROGRESS: at 4.44% examples, 139312 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:32:10: EPOCH 3 - PROGRESS: at 11.38% examples, 187544 words/s, in_qsize 21, out_qsize 1\n",
      "INFO - 11:32:12: EPOCH 3 - PROGRESS: at 17.35% examples, 189938 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:32:13: EPOCH 3 - PROGRESS: at 24.46% examples, 201393 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:32:14: EPOCH 3 - PROGRESS: at 31.45% examples, 206186 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:32:15: EPOCH 3 - PROGRESS: at 38.48% examples, 209883 words/s, in_qsize 22, out_qsize 1\n",
      "INFO - 11:32:16: EPOCH 3 - PROGRESS: at 44.67% examples, 207227 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:32:17: EPOCH 3 - PROGRESS: at 51.92% examples, 210572 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:32:18: EPOCH 3 - PROGRESS: at 57.98% examples, 208946 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:32:19: EPOCH 3 - PROGRESS: at 64.45% examples, 209890 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:32:20: EPOCH 3 - PROGRESS: at 70.61% examples, 208502 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:32:21: EPOCH 3 - PROGRESS: at 77.05% examples, 208910 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:32:22: EPOCH 3 - PROGRESS: at 84.12% examples, 210566 words/s, in_qsize 19, out_qsize 0\n",
      "INFO - 11:32:23: EPOCH 3 - PROGRESS: at 90.39% examples, 210469 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:32:24: EPOCH 3 - PROGRESS: at 95.45% examples, 207390 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:32:24: EPOCH 3: training on 5701144 raw words (3339319 effective words) took 15.9s, 210208 effective words/s\n",
      "INFO - 11:32:25: EPOCH 4 - PROGRESS: at 4.79% examples, 153413 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:32:26: EPOCH 4 - PROGRESS: at 11.07% examples, 182980 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:32:27: EPOCH 4 - PROGRESS: at 18.03% examples, 198114 words/s, in_qsize 20, out_qsize 0\n",
      "INFO - 11:32:28: EPOCH 4 - PROGRESS: at 24.27% examples, 200223 words/s, in_qsize 21, out_qsize 1\n",
      "INFO - 11:32:30: EPOCH 4 - PROGRESS: at 30.60% examples, 196912 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:32:31: EPOCH 4 - PROGRESS: at 37.76% examples, 203672 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:32:32: EPOCH 4 - PROGRESS: at 43.81% examples, 202933 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:32:33: EPOCH 4 - PROGRESS: at 49.89% examples, 202473 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:32:34: EPOCH 4 - PROGRESS: at 56.91% examples, 205277 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:32:35: EPOCH 4 - PROGRESS: at 63.77% examples, 207405 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:32:36: EPOCH 4 - PROGRESS: at 71.12% examples, 209945 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:32:37: EPOCH 4 - PROGRESS: at 77.41% examples, 208533 words/s, in_qsize 21, out_qsize 1\n",
      "INFO - 11:32:38: EPOCH 4 - PROGRESS: at 84.62% examples, 210272 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:32:39: EPOCH 4 - PROGRESS: at 90.39% examples, 208049 words/s, in_qsize 21, out_qsize 1\n",
      "INFO - 11:32:40: EPOCH 4 - PROGRESS: at 97.18% examples, 209176 words/s, in_qsize 16, out_qsize 0\n",
      "INFO - 11:32:40: EPOCH 4: training on 5701144 raw words (3341003 effective words) took 15.8s, 211055 effective words/s\n",
      "INFO - 11:32:41: EPOCH 5 - PROGRESS: at 4.79% examples, 153540 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:32:42: EPOCH 5 - PROGRESS: at 11.23% examples, 186369 words/s, in_qsize 16, out_qsize 2\n",
      "INFO - 11:32:43: EPOCH 5 - PROGRESS: at 17.35% examples, 190776 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:32:44: EPOCH 5 - PROGRESS: at 23.37% examples, 191603 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:32:45: EPOCH 5 - PROGRESS: at 30.23% examples, 197100 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:32:46: EPOCH 5 - PROGRESS: at 35.99% examples, 190752 words/s, in_qsize 21, out_qsize 1\n",
      "INFO - 11:32:47: EPOCH 5 - PROGRESS: at 42.77% examples, 195578 words/s, in_qsize 18, out_qsize 1\n",
      "INFO - 11:32:48: EPOCH 5 - PROGRESS: at 49.01% examples, 197150 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:32:50: EPOCH 5 - PROGRESS: at 54.80% examples, 194875 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:32:51: EPOCH 5 - PROGRESS: at 61.76% examples, 198234 words/s, in_qsize 19, out_qsize 0\n",
      "INFO - 11:32:52: EPOCH 5 - PROGRESS: at 68.40% examples, 199491 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:32:53: EPOCH 5 - PROGRESS: at 73.76% examples, 197721 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:32:54: EPOCH 5 - PROGRESS: at 80.61% examples, 199846 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:32:55: EPOCH 5 - PROGRESS: at 86.92% examples, 200781 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:32:56: EPOCH 5 - PROGRESS: at 93.33% examples, 201572 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:32:57: EPOCH 5: training on 5701144 raw words (3340152 effective words) took 16.4s, 203273 effective words/s\n",
      "INFO - 11:32:58: EPOCH 6 - PROGRESS: at 4.45% examples, 141213 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:32:59: EPOCH 6 - PROGRESS: at 11.23% examples, 184996 words/s, in_qsize 19, out_qsize 0\n",
      "INFO - 11:33:00: EPOCH 6 - PROGRESS: at 17.54% examples, 186129 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:33:01: EPOCH 6 - PROGRESS: at 24.83% examples, 199178 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:33:02: EPOCH 6 - PROGRESS: at 30.05% examples, 192105 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:33:03: EPOCH 6 - PROGRESS: at 36.33% examples, 194494 words/s, in_qsize 19, out_qsize 2\n",
      "INFO - 11:33:04: EPOCH 6 - PROGRESS: at 42.75% examples, 196982 words/s, in_qsize 21, out_qsize 2\n",
      "INFO - 11:33:05: EPOCH 6 - PROGRESS: at 49.54% examples, 200075 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:33:06: EPOCH 6 - PROGRESS: at 55.66% examples, 198087 words/s, in_qsize 21, out_qsize 1\n",
      "INFO - 11:33:07: EPOCH 6 - PROGRESS: at 62.60% examples, 201080 words/s, in_qsize 22, out_qsize 1\n",
      "INFO - 11:33:08: EPOCH 6 - PROGRESS: at 68.89% examples, 201661 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:33:09: EPOCH 6 - PROGRESS: at 74.80% examples, 200652 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:33:10: EPOCH 6 - PROGRESS: at 81.87% examples, 202925 words/s, in_qsize 20, out_qsize 0\n",
      "INFO - 11:33:11: EPOCH 6 - PROGRESS: at 87.97% examples, 203209 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:33:12: EPOCH 6 - PROGRESS: at 93.50% examples, 202057 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:33:13: EPOCH 6: training on 5701144 raw words (3338982 effective words) took 16.3s, 205178 effective words/s\n",
      "INFO - 11:33:14: EPOCH 7 - PROGRESS: at 5.12% examples, 168118 words/s, in_qsize 18, out_qsize 1\n",
      "INFO - 11:33:15: EPOCH 7 - PROGRESS: at 11.06% examples, 176038 words/s, in_qsize 21, out_qsize 2\n",
      "INFO - 11:33:16: EPOCH 7 - PROGRESS: at 18.53% examples, 198259 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:33:17: EPOCH 7 - PROGRESS: at 25.50% examples, 205587 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:33:18: EPOCH 7 - PROGRESS: at 31.26% examples, 202391 words/s, in_qsize 19, out_qsize 1\n",
      "INFO - 11:33:19: EPOCH 7 - PROGRESS: at 38.31% examples, 206369 words/s, in_qsize 20, out_qsize 0\n",
      "INFO - 11:33:20: EPOCH 7 - PROGRESS: at 44.49% examples, 206179 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:33:21: EPOCH 7 - PROGRESS: at 51.41% examples, 207476 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:33:22: EPOCH 7 - PROGRESS: at 57.92% examples, 207576 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:33:23: EPOCH 7 - PROGRESS: at 64.99% examples, 210000 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:33:24: EPOCH 7 - PROGRESS: at 70.78% examples, 207797 words/s, in_qsize 18, out_qsize 4\n",
      "INFO - 11:33:25: EPOCH 7 - PROGRESS: at 78.29% examples, 210927 words/s, in_qsize 20, out_qsize 2\n",
      "INFO - 11:33:26: EPOCH 7 - PROGRESS: at 84.46% examples, 210203 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:33:27: EPOCH 7 - PROGRESS: at 91.22% examples, 211634 words/s, in_qsize 20, out_qsize 0\n",
      "INFO - 11:33:28: EPOCH 7 - PROGRESS: at 97.89% examples, 212129 words/s, in_qsize 12, out_qsize 0\n",
      "INFO - 11:33:29: EPOCH 7: training on 5701144 raw words (3339698 effective words) took 15.6s, 213730 effective words/s\n",
      "INFO - 11:33:30: EPOCH 8 - PROGRESS: at 5.63% examples, 179975 words/s, in_qsize 17, out_qsize 0\n",
      "INFO - 11:33:31: EPOCH 8 - PROGRESS: at 11.40% examples, 186453 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:33:32: EPOCH 8 - PROGRESS: at 17.18% examples, 183287 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:33:33: EPOCH 8 - PROGRESS: at 22.66% examples, 182723 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:33:34: EPOCH 8 - PROGRESS: at 28.27% examples, 182815 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:33:35: EPOCH 8 - PROGRESS: at 34.57% examples, 184971 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:33:36: EPOCH 8 - PROGRESS: at 41.01% examples, 188529 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:33:37: EPOCH 8 - PROGRESS: at 47.43% examples, 191025 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:33:38: EPOCH 8 - PROGRESS: at 54.31% examples, 194505 words/s, in_qsize 21, out_qsize 1\n",
      "INFO - 11:33:39: EPOCH 8 - PROGRESS: at 60.89% examples, 197015 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:33:40: EPOCH 8 - PROGRESS: at 67.14% examples, 197314 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:33:41: EPOCH 8 - PROGRESS: at 73.23% examples, 197792 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:33:42: EPOCH 8 - PROGRESS: at 79.91% examples, 198630 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:33:43: EPOCH 8 - PROGRESS: at 85.97% examples, 198731 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:33:44: EPOCH 8 - PROGRESS: at 92.29% examples, 199091 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:33:45: EPOCH 8: training on 5701144 raw words (3339398 effective words) took 16.5s, 202558 effective words/s\n",
      "INFO - 11:33:46: EPOCH 9 - PROGRESS: at 4.78% examples, 150369 words/s, in_qsize 14, out_qsize 0\n",
      "INFO - 11:33:47: EPOCH 9 - PROGRESS: at 11.40% examples, 178349 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:33:48: EPOCH 9 - PROGRESS: at 17.01% examples, 179944 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:33:49: EPOCH 9 - PROGRESS: at 22.47% examples, 181224 words/s, in_qsize 20, out_qsize 0\n",
      "INFO - 11:33:50: EPOCH 9 - PROGRESS: at 28.63% examples, 184895 words/s, in_qsize 20, out_qsize 0\n",
      "INFO - 11:33:51: EPOCH 9 - PROGRESS: at 34.57% examples, 186641 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:33:52: EPOCH 9 - PROGRESS: at 41.21% examples, 191423 words/s, in_qsize 21, out_qsize 1\n",
      "INFO - 11:33:53: EPOCH 9 - PROGRESS: at 47.08% examples, 191222 words/s, in_qsize 21, out_qsize 1\n",
      "INFO - 11:33:54: EPOCH 9 - PROGRESS: at 54.13% examples, 194758 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:33:55: EPOCH 9 - PROGRESS: at 60.21% examples, 194929 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:33:56: EPOCH 9 - PROGRESS: at 66.07% examples, 194928 words/s, in_qsize 20, out_qsize 0\n",
      "INFO - 11:33:57: EPOCH 9 - PROGRESS: at 71.64% examples, 193797 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:33:58: EPOCH 9 - PROGRESS: at 77.93% examples, 194465 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:33:59: EPOCH 9 - PROGRESS: at 83.78% examples, 193981 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:34:00: EPOCH 9 - PROGRESS: at 89.82% examples, 194716 words/s, in_qsize 17, out_qsize 2\n",
      "INFO - 11:34:01: EPOCH 9 - PROGRESS: at 97.01% examples, 197261 words/s, in_qsize 17, out_qsize 0\n",
      "INFO - 11:34:02: EPOCH 9: training on 5701144 raw words (3340689 effective words) took 16.8s, 199061 effective words/s\n",
      "INFO - 11:34:03: EPOCH 10 - PROGRESS: at 4.44% examples, 144435 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:34:04: EPOCH 10 - PROGRESS: at 10.77% examples, 166780 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:34:05: EPOCH 10 - PROGRESS: at 18.03% examples, 183564 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:34:06: EPOCH 10 - PROGRESS: at 24.98% examples, 194096 words/s, in_qsize 21, out_qsize 1\n",
      "INFO - 11:34:07: EPOCH 10 - PROGRESS: at 31.45% examples, 196376 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:34:08: EPOCH 10 - PROGRESS: at 38.31% examples, 201194 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:34:09: EPOCH 10 - PROGRESS: at 45.16% examples, 204724 words/s, in_qsize 19, out_qsize 2\n",
      "INFO - 11:34:10: EPOCH 10 - PROGRESS: at 51.75% examples, 206466 words/s, in_qsize 21, out_qsize 4\n",
      "INFO - 11:34:11: EPOCH 10 - PROGRESS: at 59.54% examples, 208590 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:34:12: EPOCH 10 - PROGRESS: at 66.08% examples, 209369 words/s, in_qsize 19, out_qsize 3\n",
      "INFO - 11:34:13: EPOCH 10 - PROGRESS: at 73.39% examples, 212030 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:34:14: EPOCH 10 - PROGRESS: at 80.26% examples, 212261 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:34:15: EPOCH 10 - PROGRESS: at 85.76% examples, 210142 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:34:16: EPOCH 10 - PROGRESS: at 92.81% examples, 212051 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:34:17: EPOCH 10 - PROGRESS: at 99.50% examples, 212536 words/s, in_qsize 3, out_qsize 1\n",
      "INFO - 11:34:18: EPOCH 10: training on 5701144 raw words (3340410 effective words) took 15.7s, 212990 effective words/s\n",
      "INFO - 11:34:19: EPOCH 11 - PROGRESS: at 4.61% examples, 144564 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:34:20: EPOCH 11 - PROGRESS: at 11.54% examples, 183887 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:34:21: EPOCH 11 - PROGRESS: at 17.01% examples, 182559 words/s, in_qsize 17, out_qsize 5\n",
      "INFO - 11:34:22: EPOCH 11 - PROGRESS: at 24.12% examples, 195635 words/s, in_qsize 19, out_qsize 1\n",
      "INFO - 11:34:23: EPOCH 11 - PROGRESS: at 30.60% examples, 197502 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:34:24: EPOCH 11 - PROGRESS: at 37.23% examples, 200550 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:34:25: EPOCH 11 - PROGRESS: at 43.81% examples, 202933 words/s, in_qsize 20, out_qsize 0\n",
      "INFO - 11:34:26: EPOCH 11 - PROGRESS: at 50.59% examples, 204592 words/s, in_qsize 21, out_qsize 1\n",
      "INFO - 11:34:27: EPOCH 11 - PROGRESS: at 57.24% examples, 205996 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:34:28: EPOCH 11 - PROGRESS: at 64.12% examples, 207406 words/s, in_qsize 21, out_qsize 1\n",
      "INFO - 11:34:29: EPOCH 11 - PROGRESS: at 69.73% examples, 205082 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:34:30: EPOCH 11 - PROGRESS: at 75.99% examples, 205402 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:34:31: EPOCH 11 - PROGRESS: at 82.20% examples, 204663 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:34:32: EPOCH 11 - PROGRESS: at 88.47% examples, 205136 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:34:33: EPOCH 11 - PROGRESS: at 94.37% examples, 204212 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:34:34: EPOCH 11: training on 5701144 raw words (3339841 effective words) took 16.1s, 207608 effective words/s\n",
      "INFO - 11:34:35: EPOCH 12 - PROGRESS: at 4.26% examples, 135996 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:34:36: EPOCH 12 - PROGRESS: at 11.38% examples, 188786 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:34:37: EPOCH 12 - PROGRESS: at 17.67% examples, 193316 words/s, in_qsize 18, out_qsize 3\n",
      "INFO - 11:34:38: EPOCH 12 - PROGRESS: at 24.98% examples, 203882 words/s, in_qsize 18, out_qsize 0\n",
      "INFO - 11:34:39: EPOCH 12 - PROGRESS: at 31.26% examples, 204395 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:34:40: EPOCH 12 - PROGRESS: at 37.75% examples, 206148 words/s, in_qsize 20, out_qsize 2\n",
      "INFO - 11:34:41: EPOCH 12 - PROGRESS: at 45.16% examples, 210109 words/s, in_qsize 22, out_qsize 1\n",
      "INFO - 11:34:42: EPOCH 12 - PROGRESS: at 51.41% examples, 209472 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:34:43: EPOCH 12 - PROGRESS: at 58.53% examples, 211878 words/s, in_qsize 19, out_qsize 1\n",
      "INFO - 11:34:44: EPOCH 12 - PROGRESS: at 64.27% examples, 208575 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:34:45: EPOCH 12 - PROGRESS: at 70.95% examples, 208804 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:34:46: EPOCH 12 - PROGRESS: at 77.08% examples, 208041 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:34:47: EPOCH 12 - PROGRESS: at 83.95% examples, 209446 words/s, in_qsize 19, out_qsize 0\n",
      "INFO - 11:34:48: EPOCH 12 - PROGRESS: at 90.20% examples, 207911 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:34:49: EPOCH 12 - PROGRESS: at 97.38% examples, 209709 words/s, in_qsize 15, out_qsize 0\n",
      "INFO - 11:34:49: EPOCH 12: training on 5701144 raw words (3340498 effective words) took 15.8s, 212056 effective words/s\n",
      "INFO - 11:34:50: EPOCH 13 - PROGRESS: at 5.14% examples, 166953 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:34:51: EPOCH 13 - PROGRESS: at 10.92% examples, 181177 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:34:52: EPOCH 13 - PROGRESS: at 18.03% examples, 199222 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:34:53: EPOCH 13 - PROGRESS: at 25.34% examples, 208160 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:34:54: EPOCH 13 - PROGRESS: at 32.45% examples, 212960 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:34:55: EPOCH 13 - PROGRESS: at 39.18% examples, 214244 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:34:57: EPOCH 13 - PROGRESS: at 45.68% examples, 213864 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:34:58: EPOCH 13 - PROGRESS: at 52.50% examples, 214648 words/s, in_qsize 20, out_qsize 0\n",
      "INFO - 11:34:59: EPOCH 13 - PROGRESS: at 58.70% examples, 211517 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:35:00: EPOCH 13 - PROGRESS: at 65.53% examples, 213427 words/s, in_qsize 18, out_qsize 1\n",
      "INFO - 11:35:01: EPOCH 13 - PROGRESS: at 71.64% examples, 212076 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:35:02: EPOCH 13 - PROGRESS: at 77.76% examples, 210615 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:35:03: EPOCH 13 - PROGRESS: at 84.94% examples, 212272 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:35:04: EPOCH 13 - PROGRESS: at 91.06% examples, 211650 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:35:05: EPOCH 13 - PROGRESS: at 97.01% examples, 210588 words/s, in_qsize 17, out_qsize 0\n",
      "INFO - 11:35:05: EPOCH 13: training on 5701144 raw words (3341526 effective words) took 15.7s, 213351 effective words/s\n",
      "INFO - 11:35:06: EPOCH 14 - PROGRESS: at 5.45% examples, 175400 words/s, in_qsize 16, out_qsize 1\n",
      "INFO - 11:35:07: EPOCH 14 - PROGRESS: at 11.72% examples, 194200 words/s, in_qsize 20, out_qsize 0\n",
      "INFO - 11:35:08: EPOCH 14 - PROGRESS: at 17.83% examples, 195801 words/s, in_qsize 21, out_qsize 1\n",
      "INFO - 11:35:09: EPOCH 14 - PROGRESS: at 24.27% examples, 199192 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:35:10: EPOCH 14 - PROGRESS: at 31.62% examples, 207808 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:35:11: EPOCH 14 - PROGRESS: at 38.31% examples, 208328 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:35:12: EPOCH 14 - PROGRESS: at 45.16% examples, 210568 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:35:13: EPOCH 14 - PROGRESS: at 51.58% examples, 210477 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:35:14: EPOCH 14 - PROGRESS: at 59.22% examples, 214441 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:35:15: EPOCH 14 - PROGRESS: at 65.89% examples, 215543 words/s, in_qsize 20, out_qsize 0\n",
      "INFO - 11:35:16: EPOCH 14 - PROGRESS: at 71.82% examples, 213797 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:35:17: EPOCH 14 - PROGRESS: at 78.12% examples, 212863 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:35:18: EPOCH 14 - PROGRESS: at 84.61% examples, 212855 words/s, in_qsize 18, out_qsize 6\n",
      "INFO - 11:35:19: EPOCH 14 - PROGRESS: at 91.59% examples, 213670 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:35:20: EPOCH 14 - PROGRESS: at 99.13% examples, 215672 words/s, in_qsize 5, out_qsize 1\n",
      "INFO - 11:35:20: EPOCH 14: training on 5701144 raw words (3340227 effective words) took 15.4s, 216571 effective words/s\n",
      "INFO - 11:35:22: EPOCH 15 - PROGRESS: at 4.61% examples, 147497 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:35:23: EPOCH 15 - PROGRESS: at 10.92% examples, 177836 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:35:24: EPOCH 15 - PROGRESS: at 18.19% examples, 199515 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:35:25: EPOCH 15 - PROGRESS: at 24.98% examples, 197177 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:35:26: EPOCH 15 - PROGRESS: at 31.98% examples, 203002 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:35:27: EPOCH 15 - PROGRESS: at 39.02% examples, 206860 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:35:28: EPOCH 15 - PROGRESS: at 45.16% examples, 207194 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:35:29: EPOCH 15 - PROGRESS: at 52.69% examples, 212266 words/s, in_qsize 19, out_qsize 0\n",
      "INFO - 11:35:30: EPOCH 15 - PROGRESS: at 59.05% examples, 210808 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:35:31: EPOCH 15 - PROGRESS: at 64.64% examples, 208689 words/s, in_qsize 18, out_qsize 3\n",
      "INFO - 11:35:32: EPOCH 15 - PROGRESS: at 71.49% examples, 210146 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:35:33: EPOCH 15 - PROGRESS: at 77.93% examples, 209180 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:35:34: EPOCH 15 - PROGRESS: at 85.26% examples, 211510 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:35:35: EPOCH 15 - PROGRESS: at 92.28% examples, 212896 words/s, in_qsize 18, out_qsize 2\n",
      "INFO - 11:35:36: EPOCH 15 - PROGRESS: at 99.50% examples, 214386 words/s, in_qsize 3, out_qsize 1\n",
      "INFO - 11:35:36: EPOCH 15: training on 5701144 raw words (3339389 effective words) took 15.6s, 214630 effective words/s\n",
      "INFO - 11:35:37: EPOCH 16 - PROGRESS: at 4.96% examples, 160430 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:35:38: EPOCH 16 - PROGRESS: at 11.40% examples, 187079 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:35:39: EPOCH 16 - PROGRESS: at 18.55% examples, 202446 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:35:40: EPOCH 16 - PROGRESS: at 25.16% examples, 206161 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:35:41: EPOCH 16 - PROGRESS: at 31.26% examples, 204300 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:35:42: EPOCH 16 - PROGRESS: at 37.56% examples, 204958 words/s, in_qsize 18, out_qsize 2\n",
      "INFO - 11:35:43: EPOCH 16 - PROGRESS: at 44.99% examples, 210973 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:35:44: EPOCH 16 - PROGRESS: at 51.58% examples, 211800 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:35:45: EPOCH 16 - PROGRESS: at 57.60% examples, 208212 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:35:46: EPOCH 16 - PROGRESS: at 64.43% examples, 209256 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:35:47: EPOCH 16 - PROGRESS: at 71.64% examples, 211274 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:35:48: EPOCH 16 - PROGRESS: at 77.59% examples, 210024 words/s, in_qsize 18, out_qsize 4\n",
      "INFO - 11:35:49: EPOCH 16 - PROGRESS: at 84.94% examples, 212493 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:35:50: EPOCH 16 - PROGRESS: at 90.89% examples, 211770 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:35:51: EPOCH 16 - PROGRESS: at 97.89% examples, 212916 words/s, in_qsize 12, out_qsize 0\n",
      "INFO - 11:35:52: EPOCH 16: training on 5701144 raw words (3339947 effective words) took 15.5s, 215054 effective words/s\n",
      "INFO - 11:35:53: EPOCH 17 - PROGRESS: at 4.43% examples, 142274 words/s, in_qsize 21, out_qsize 1\n",
      "INFO - 11:35:54: EPOCH 17 - PROGRESS: at 11.55% examples, 191516 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:35:55: EPOCH 17 - PROGRESS: at 18.36% examples, 198251 words/s, in_qsize 21, out_qsize 1\n",
      "INFO - 11:35:56: EPOCH 17 - PROGRESS: at 23.87% examples, 194071 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:35:57: EPOCH 17 - PROGRESS: at 31.26% examples, 203534 words/s, in_qsize 19, out_qsize 0\n",
      "INFO - 11:35:58: EPOCH 17 - PROGRESS: at 37.23% examples, 201794 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:35:59: EPOCH 17 - PROGRESS: at 44.17% examples, 204982 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:36:00: EPOCH 17 - PROGRESS: at 50.21% examples, 202630 words/s, in_qsize 21, out_qsize 1\n",
      "INFO - 11:36:01: EPOCH 17 - PROGRESS: at 57.43% examples, 204505 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:02: EPOCH 17 - PROGRESS: at 64.27% examples, 206677 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:03: EPOCH 17 - PROGRESS: at 71.64% examples, 209891 words/s, in_qsize 20, out_qsize 0\n",
      "INFO - 11:36:04: EPOCH 17 - PROGRESS: at 77.93% examples, 209566 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:05: EPOCH 17 - PROGRESS: at 85.11% examples, 211540 words/s, in_qsize 18, out_qsize 0\n",
      "INFO - 11:36:06: EPOCH 17 - PROGRESS: at 90.89% examples, 210566 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:36:07: EPOCH 17 - PROGRESS: at 98.08% examples, 212280 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 11:36:07: EPOCH 17: training on 5701144 raw words (3340349 effective words) took 15.6s, 213810 effective words/s\n",
      "INFO - 11:36:08: EPOCH 18 - PROGRESS: at 5.30% examples, 158692 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:09: EPOCH 18 - PROGRESS: at 10.78% examples, 171151 words/s, in_qsize 17, out_qsize 4\n",
      "INFO - 11:36:10: EPOCH 18 - PROGRESS: at 17.87% examples, 191750 words/s, in_qsize 20, out_qsize 2\n",
      "INFO - 11:36:11: EPOCH 18 - PROGRESS: at 24.98% examples, 200741 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:12: EPOCH 18 - PROGRESS: at 31.28% examples, 199785 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:36:13: EPOCH 18 - PROGRESS: at 38.84% examples, 206754 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:15: EPOCH 18 - PROGRESS: at 44.67% examples, 204953 words/s, in_qsize 21, out_qsize 1\n",
      "INFO - 11:36:16: EPOCH 18 - PROGRESS: at 51.08% examples, 205163 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:17: EPOCH 18 - PROGRESS: at 57.60% examples, 206124 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:36:18: EPOCH 18 - PROGRESS: at 64.27% examples, 207839 words/s, in_qsize 21, out_qsize 1\n",
      "INFO - 11:36:19: EPOCH 18 - PROGRESS: at 70.09% examples, 206167 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:36:20: EPOCH 18 - PROGRESS: at 76.90% examples, 206738 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:36:21: EPOCH 18 - PROGRESS: at 83.26% examples, 206670 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:22: EPOCH 18 - PROGRESS: at 90.20% examples, 208241 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:23: EPOCH 18 - PROGRESS: at 97.38% examples, 209792 words/s, in_qsize 15, out_qsize 0\n",
      "INFO - 11:36:23: EPOCH 18: training on 5701144 raw words (3340186 effective words) took 15.8s, 211796 effective words/s\n",
      "INFO - 11:36:24: EPOCH 19 - PROGRESS: at 4.44% examples, 144651 words/s, in_qsize 19, out_qsize 0\n",
      "INFO - 11:36:25: EPOCH 19 - PROGRESS: at 11.07% examples, 185397 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:26: EPOCH 19 - PROGRESS: at 17.86% examples, 198760 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:27: EPOCH 19 - PROGRESS: at 24.98% examples, 204188 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:28: EPOCH 19 - PROGRESS: at 31.09% examples, 203921 words/s, in_qsize 17, out_qsize 5\n",
      "INFO - 11:36:29: EPOCH 19 - PROGRESS: at 38.68% examples, 211408 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:30: EPOCH 19 - PROGRESS: at 44.83% examples, 210484 words/s, in_qsize 17, out_qsize 1\n",
      "INFO - 11:36:31: EPOCH 19 - PROGRESS: at 51.10% examples, 207626 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:32: EPOCH 19 - PROGRESS: at 58.17% examples, 209033 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:33: EPOCH 19 - PROGRESS: at 64.27% examples, 208851 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:36:34: EPOCH 19 - PROGRESS: at 70.95% examples, 209786 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:35: EPOCH 19 - PROGRESS: at 78.11% examples, 211860 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:36: EPOCH 19 - PROGRESS: at 85.26% examples, 213667 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:37: EPOCH 19 - PROGRESS: at 91.57% examples, 212491 words/s, in_qsize 19, out_qsize 2\n",
      "INFO - 11:36:38: EPOCH 19 - PROGRESS: at 99.66% examples, 215854 words/s, in_qsize 2, out_qsize 1\n",
      "INFO - 11:36:38: EPOCH 19: training on 5701144 raw words (3340695 effective words) took 15.4s, 216295 effective words/s\n",
      "INFO - 11:36:39: EPOCH 20 - PROGRESS: at 4.79% examples, 155150 words/s, in_qsize 19, out_qsize 0\n",
      "INFO - 11:36:40: EPOCH 20 - PROGRESS: at 11.89% examples, 198901 words/s, in_qsize 18, out_qsize 1\n",
      "INFO - 11:36:42: EPOCH 20 - PROGRESS: at 18.22% examples, 197843 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:43: EPOCH 20 - PROGRESS: at 25.87% examples, 211003 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:44: EPOCH 20 - PROGRESS: at 32.28% examples, 206669 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:45: EPOCH 20 - PROGRESS: at 39.51% examples, 211617 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:46: EPOCH 20 - PROGRESS: at 45.51% examples, 210513 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:36:47: EPOCH 20 - PROGRESS: at 52.67% examples, 212534 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:48: EPOCH 20 - PROGRESS: at 58.71% examples, 210083 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:36:49: EPOCH 20 - PROGRESS: at 66.43% examples, 213905 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:36:50: EPOCH 20 - PROGRESS: at 73.22% examples, 214567 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:36:51: EPOCH 20 - PROGRESS: at 79.93% examples, 214139 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:52: EPOCH 20 - PROGRESS: at 86.29% examples, 214169 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:53: EPOCH 20 - PROGRESS: at 93.00% examples, 214981 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:54: EPOCH 20: training on 5701144 raw words (3339871 effective words) took 15.3s, 218205 effective words/s\n",
      "INFO - 11:36:55: EPOCH 21 - PROGRESS: at 4.61% examples, 146126 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:56: EPOCH 21 - PROGRESS: at 11.40% examples, 182694 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:57: EPOCH 21 - PROGRESS: at 17.52% examples, 182117 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:36:58: EPOCH 21 - PROGRESS: at 24.46% examples, 193027 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:36:59: EPOCH 21 - PROGRESS: at 29.86% examples, 189397 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:37:00: EPOCH 21 - PROGRESS: at 37.20% examples, 198097 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:37:01: EPOCH 21 - PROGRESS: at 43.99% examples, 201596 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:37:02: EPOCH 21 - PROGRESS: at 49.69% examples, 200432 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:37:03: EPOCH 21 - PROGRESS: at 57.08% examples, 204947 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:37:04: EPOCH 21 - PROGRESS: at 62.80% examples, 203012 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:37:05: EPOCH 21 - PROGRESS: at 69.55% examples, 204629 words/s, in_qsize 18, out_qsize 0\n",
      "INFO - 11:37:06: EPOCH 21 - PROGRESS: at 75.49% examples, 202648 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:37:07: EPOCH 21 - PROGRESS: at 82.55% examples, 204643 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:37:08: EPOCH 21 - PROGRESS: at 87.97% examples, 203020 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:37:09: EPOCH 21 - PROGRESS: at 95.59% examples, 205975 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:37:10: EPOCH 21: training on 5701144 raw words (3340430 effective words) took 16.0s, 209426 effective words/s\n",
      "INFO - 11:37:11: EPOCH 22 - PROGRESS: at 4.44% examples, 143978 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:37:12: EPOCH 22 - PROGRESS: at 11.72% examples, 195578 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:37:13: EPOCH 22 - PROGRESS: at 18.36% examples, 200123 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:37:14: EPOCH 22 - PROGRESS: at 25.50% examples, 206824 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:37:15: EPOCH 22 - PROGRESS: at 32.65% examples, 212334 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:37:16: EPOCH 22 - PROGRESS: at 38.49% examples, 208509 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:37:17: EPOCH 22 - PROGRESS: at 45.68% examples, 213171 words/s, in_qsize 18, out_qsize 0\n",
      "INFO - 11:37:18: EPOCH 22 - PROGRESS: at 51.41% examples, 207383 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:37:19: EPOCH 22 - PROGRESS: at 58.53% examples, 209761 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:37:20: EPOCH 22 - PROGRESS: at 64.10% examples, 205552 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:37:21: EPOCH 22 - PROGRESS: at 71.12% examples, 207734 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:37:22: EPOCH 22 - PROGRESS: at 76.90% examples, 206247 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:37:23: EPOCH 22 - PROGRESS: at 84.46% examples, 208940 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:37:24: EPOCH 22 - PROGRESS: at 90.56% examples, 208118 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:37:25: EPOCH 22 - PROGRESS: at 97.72% examples, 209991 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 11:37:25: EPOCH 22: training on 5701144 raw words (3340042 effective words) took 15.7s, 212268 effective words/s\n",
      "INFO - 11:37:27: EPOCH 23 - PROGRESS: at 4.44% examples, 138504 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:37:28: EPOCH 23 - PROGRESS: at 11.22% examples, 182942 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:37:29: EPOCH 23 - PROGRESS: at 18.20% examples, 197906 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:37:30: EPOCH 23 - PROGRESS: at 25.32% examples, 207364 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:37:31: EPOCH 23 - PROGRESS: at 31.62% examples, 206779 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:37:32: EPOCH 23 - PROGRESS: at 37.57% examples, 203654 words/s, in_qsize 18, out_qsize 3\n",
      "INFO - 11:37:33: EPOCH 23 - PROGRESS: at 44.99% examples, 207990 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:37:34: EPOCH 23 - PROGRESS: at 51.92% examples, 209779 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:37:35: EPOCH 23 - PROGRESS: at 58.86% examples, 211510 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:37:36: EPOCH 23 - PROGRESS: at 66.08% examples, 214152 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:37:37: EPOCH 23 - PROGRESS: at 72.18% examples, 213165 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:37:38: EPOCH 23 - PROGRESS: at 79.19% examples, 214237 words/s, in_qsize 17, out_qsize 3\n",
      "INFO - 11:37:39: EPOCH 23 - PROGRESS: at 86.94% examples, 217657 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:37:40: EPOCH 23 - PROGRESS: at 93.16% examples, 216846 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:37:41: EPOCH 23: training on 5701144 raw words (3341588 effective words) took 15.1s, 220586 effective words/s\n",
      "INFO - 11:37:42: EPOCH 24 - PROGRESS: at 4.61% examples, 147560 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:37:43: EPOCH 24 - PROGRESS: at 11.72% examples, 195320 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:37:44: EPOCH 24 - PROGRESS: at 17.35% examples, 191656 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:37:45: EPOCH 24 - PROGRESS: at 24.64% examples, 202314 words/s, in_qsize 20, out_qsize 0\n",
      "INFO - 11:37:46: EPOCH 24 - PROGRESS: at 31.07% examples, 203728 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:37:47: EPOCH 24 - PROGRESS: at 38.12% examples, 204063 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:37:48: EPOCH 24 - PROGRESS: at 43.61% examples, 200615 words/s, in_qsize 15, out_qsize 6\n",
      "INFO - 11:37:49: EPOCH 24 - PROGRESS: at 51.10% examples, 205852 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:37:50: EPOCH 24 - PROGRESS: at 56.91% examples, 203393 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:37:51: EPOCH 24 - PROGRESS: at 63.60% examples, 204869 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:37:52: EPOCH 24 - PROGRESS: at 70.95% examples, 208045 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:37:53: EPOCH 24 - PROGRESS: at 78.30% examples, 208671 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:37:54: EPOCH 24 - PROGRESS: at 85.45% examples, 210654 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:37:55: EPOCH 24 - PROGRESS: at 91.96% examples, 210045 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:37:56: EPOCH 24 - PROGRESS: at 98.77% examples, 210786 words/s, in_qsize 7, out_qsize 1\n",
      "INFO - 11:37:56: EPOCH 24: training on 5701144 raw words (3340692 effective words) took 15.7s, 212842 effective words/s\n",
      "INFO - 11:37:57: EPOCH 25 - PROGRESS: at 4.62% examples, 148059 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:37:58: EPOCH 25 - PROGRESS: at 11.55% examples, 190455 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:37:59: EPOCH 25 - PROGRESS: at 17.87% examples, 196465 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:38:00: EPOCH 25 - PROGRESS: at 25.34% examples, 208582 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:38:01: EPOCH 25 - PROGRESS: at 32.48% examples, 213254 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:38:02: EPOCH 25 - PROGRESS: at 39.51% examples, 216013 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:38:04: EPOCH 25 - PROGRESS: at 45.00% examples, 207760 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:38:05: EPOCH 25 - PROGRESS: at 51.75% examples, 209363 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:38:06: EPOCH 25 - PROGRESS: at 57.98% examples, 208242 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:38:07: EPOCH 25 - PROGRESS: at 64.14% examples, 207728 words/s, in_qsize 18, out_qsize 2\n",
      "INFO - 11:38:08: EPOCH 25 - PROGRESS: at 71.49% examples, 210958 words/s, in_qsize 18, out_qsize 0\n",
      "INFO - 11:38:09: EPOCH 25 - PROGRESS: at 78.47% examples, 212382 words/s, in_qsize 21, out_qsize 1\n",
      "INFO - 11:38:10: EPOCH 25 - PROGRESS: at 84.62% examples, 210763 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:38:11: EPOCH 25 - PROGRESS: at 91.06% examples, 211178 words/s, in_qsize 19, out_qsize 2\n",
      "INFO - 11:38:12: EPOCH 25 - PROGRESS: at 98.77% examples, 213926 words/s, in_qsize 7, out_qsize 1\n",
      "INFO - 11:38:12: EPOCH 25: training on 5701144 raw words (3341338 effective words) took 15.6s, 214666 effective words/s\n",
      "INFO - 11:38:13: EPOCH 26 - PROGRESS: at 4.96% examples, 153946 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:38:14: EPOCH 26 - PROGRESS: at 10.43% examples, 168243 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:38:15: EPOCH 26 - PROGRESS: at 17.67% examples, 192611 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:38:16: EPOCH 26 - PROGRESS: at 23.89% examples, 196059 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:38:17: EPOCH 26 - PROGRESS: at 31.62% examples, 206496 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:38:18: EPOCH 26 - PROGRESS: at 37.93% examples, 206612 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:38:19: EPOCH 26 - PROGRESS: at 44.66% examples, 208923 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:38:20: EPOCH 26 - PROGRESS: at 51.58% examples, 211273 words/s, in_qsize 18, out_qsize 3\n",
      "INFO - 11:38:21: EPOCH 26 - PROGRESS: at 59.22% examples, 215217 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:38:22: EPOCH 26 - PROGRESS: at 64.27% examples, 210733 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:38:23: EPOCH 26 - PROGRESS: at 71.31% examples, 209004 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:38:24: EPOCH 26 - PROGRESS: at 78.30% examples, 210706 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:38:25: EPOCH 26 - PROGRESS: at 84.12% examples, 208463 words/s, in_qsize 20, out_qsize 2\n",
      "INFO - 11:38:26: EPOCH 26 - PROGRESS: at 91.05% examples, 210360 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:38:27: EPOCH 26 - PROGRESS: at 98.08% examples, 210506 words/s, in_qsize 11, out_qsize 0\n",
      "INFO - 11:38:28: EPOCH 26: training on 5701144 raw words (3338386 effective words) took 15.7s, 212735 effective words/s\n",
      "INFO - 11:38:29: EPOCH 27 - PROGRESS: at 5.14% examples, 158566 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:38:30: EPOCH 27 - PROGRESS: at 11.69% examples, 189469 words/s, in_qsize 21, out_qsize 1\n",
      "INFO - 11:38:31: EPOCH 27 - PROGRESS: at 19.46% examples, 208065 words/s, in_qsize 19, out_qsize 2\n",
      "INFO - 11:38:32: EPOCH 27 - PROGRESS: at 26.89% examples, 216365 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:38:33: EPOCH 27 - PROGRESS: at 33.53% examples, 216524 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:38:34: EPOCH 27 - PROGRESS: at 40.02% examples, 215529 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:38:35: EPOCH 27 - PROGRESS: at 47.26% examples, 219498 words/s, in_qsize 18, out_qsize 0\n",
      "INFO - 11:38:36: EPOCH 27 - PROGRESS: at 53.59% examples, 214430 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:38:37: EPOCH 27 - PROGRESS: at 60.39% examples, 215652 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:38:38: EPOCH 27 - PROGRESS: at 66.97% examples, 215904 words/s, in_qsize 20, out_qsize 2\n",
      "INFO - 11:38:39: EPOCH 27 - PROGRESS: at 74.45% examples, 218707 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:38:40: EPOCH 27 - PROGRESS: at 80.44% examples, 216787 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:38:41: EPOCH 27 - PROGRESS: at 87.30% examples, 217380 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:38:42: EPOCH 27 - PROGRESS: at 93.65% examples, 216796 words/s, in_qsize 19, out_qsize 0\n",
      "INFO - 11:38:43: EPOCH 27: training on 5701144 raw words (3340578 effective words) took 15.2s, 219396 effective words/s\n",
      "INFO - 11:38:44: EPOCH 28 - PROGRESS: at 4.96% examples, 157134 words/s, in_qsize 20, out_qsize 0\n",
      "INFO - 11:38:45: EPOCH 28 - PROGRESS: at 10.44% examples, 171124 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:38:46: EPOCH 28 - PROGRESS: at 16.66% examples, 183483 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:38:47: EPOCH 28 - PROGRESS: at 23.54% examples, 194840 words/s, in_qsize 19, out_qsize 1\n",
      "INFO - 11:38:48: EPOCH 28 - PROGRESS: at 29.18% examples, 188968 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:38:49: EPOCH 28 - PROGRESS: at 36.38% examples, 196597 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:38:50: EPOCH 28 - PROGRESS: at 43.62% examples, 203243 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:38:51: EPOCH 28 - PROGRESS: at 50.23% examples, 204799 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:38:52: EPOCH 28 - PROGRESS: at 57.26% examples, 207238 words/s, in_qsize 18, out_qsize 3\n",
      "INFO - 11:38:53: EPOCH 28 - PROGRESS: at 63.43% examples, 207331 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:38:54: EPOCH 28 - PROGRESS: at 69.73% examples, 207037 words/s, in_qsize 21, out_qsize 1\n",
      "INFO - 11:38:55: EPOCH 28 - PROGRESS: at 76.56% examples, 208040 words/s, in_qsize 21, out_qsize 1\n",
      "INFO - 11:38:56: EPOCH 28 - PROGRESS: at 84.12% examples, 211025 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:38:57: EPOCH 28 - PROGRESS: at 90.03% examples, 210129 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:38:58: EPOCH 28 - PROGRESS: at 97.55% examples, 212356 words/s, in_qsize 14, out_qsize 0\n",
      "INFO - 11:38:58: EPOCH 28: training on 5701144 raw words (3340689 effective words) took 15.6s, 214287 effective words/s\n",
      "INFO - 11:38:59: EPOCH 29 - PROGRESS: at 4.79% examples, 155676 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:39:01: EPOCH 29 - PROGRESS: at 11.42% examples, 184653 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 11:39:02: EPOCH 29 - PROGRESS: at 18.36% examples, 199941 words/s, in_qsize 17, out_qsize 2\n",
      "INFO - 11:39:03: EPOCH 29 - PROGRESS: at 24.98% examples, 204158 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:39:04: EPOCH 29 - PROGRESS: at 30.92% examples, 202480 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:39:05: EPOCH 29 - PROGRESS: at 37.93% examples, 207400 words/s, in_qsize 18, out_qsize 0\n",
      "INFO - 11:39:06: EPOCH 29 - PROGRESS: at 44.33% examples, 207976 words/s, in_qsize 19, out_qsize 0\n",
      "INFO - 11:39:07: EPOCH 29 - PROGRESS: at 50.42% examples, 206757 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:39:08: EPOCH 29 - PROGRESS: at 57.08% examples, 206978 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:39:09: EPOCH 29 - PROGRESS: at 63.75% examples, 208722 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:39:10: EPOCH 29 - PROGRESS: at 70.09% examples, 208289 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:39:11: EPOCH 29 - PROGRESS: at 76.56% examples, 207582 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:39:12: EPOCH 29 - PROGRESS: at 83.78% examples, 209106 words/s, in_qsize 22, out_qsize 0\n",
      "INFO - 11:39:13: EPOCH 29 - PROGRESS: at 89.17% examples, 207371 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:39:14: EPOCH 29 - PROGRESS: at 95.25% examples, 207057 words/s, in_qsize 21, out_qsize 0\n",
      "INFO - 11:39:14: EPOCH 29: training on 5701144 raw words (3340469 effective words) took 15.9s, 210229 effective words/s\n",
      "INFO - 11:39:14: Word2Vec lifecycle event {'msg': 'training on 171034320 raw words (100208888 effective words) took 474.4s, 211238 effective words/s', 'datetime': '2022-06-25T11:39:14.859769', 'gensim': '4.2.0', 'python': '3.8.0 (default, Nov  6 2019, 21:49:08) \\n[GCC 7.3.0]', 'platform': 'Linux-5.13.0-51-generic-x86_64-with-glibc2.10', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 7.91 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c8a5d02a-e053-42c0-aca4-a244885d890a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11:40:40: Word2Vec lifecycle event {'fname_or_handle': 'imdb_review_w2v.bin', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-06-25T11:40:40.931394', 'gensim': '4.2.0', 'python': '3.8.0 (default, Nov  6 2019, 21:49:08) \\n[GCC 7.3.0]', 'platform': 'Linux-5.13.0-51-generic-x86_64-with-glibc2.10', 'event': 'saving'}\n",
      "INFO - 11:40:40: not storing attribute cum_table\n",
      "INFO - 11:40:40: saved imdb_review_w2v.bin\n"
     ]
    }
   ],
   "source": [
    "w2v_model.save('imdb_review_w2v.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea063c6-1e9b-4c68-ac48-7ae2ddf0fa2d",
   "metadata": {},
   "source": [
    "## Exploring the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "06a5494b-945c-48c2-aea5-e1393e16b742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batman_begin', 0.37667492032051086),\n",
       " ('david_mamet', 0.37097829580307007),\n",
       " ('batman_robin', 0.3625071942806244),\n",
       " ('nolans', 0.3601624071598053),\n",
       " ('memento', 0.3583686351776123),\n",
       " ('great', 0.3400098979473114),\n",
       " ('entire_cast', 0.32693397998809814),\n",
       " ('ridley_scott', 0.32323116064071655),\n",
       " ('excellent', 0.32223260402679443),\n",
       " ('look_forward', 0.31359919905662537)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the word is in the vocabulary before feeding in\n",
    "\n",
    "#Get most similar words\n",
    "w2v_model.wv.most_similar(positive=[\"christopher_nolan\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bdd323c8-6065-4734-8606-64e48f828853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46241245"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity(\"batman\", 'joker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "23da6ccc-8596-459d-bbb0-a718ec9decb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hulk'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.doesnt_match(['batman', 'joker', 'hulk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "33ea0cf4-82b9-4803-a2d7-8098a3752cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bridge', 0.28366515040397644),\n",
       " ('kleenex', 0.28308799862861633),\n",
       " ('port', 0.27012956142425537)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"titanic\", \"james_cameron\"], negative=[\"christopher_nolan\"], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ddf782-efe0-4ffb-b1e0-eeddc178fe41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "296e912957bd482cc6e88dcab6e634628d0861d6347ba5ff2b91c085c9501fc2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
