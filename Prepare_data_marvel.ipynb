{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7b4bd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  # For preprocessing\n",
    "import pandas as pd  # For data handling\n",
    "from time import time  # To time our operations\n",
    "from collections import defaultdict  # For word frequency\n",
    "from tqdm.notebook import tqdm\n",
    "import spacy  # For preprocessing\n",
    "import nltk\n",
    "import string\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import WordNetLemmatizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1efb5c8-2c0c-4cc4-8b34-13100a853376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/gunjan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/gunjan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/gunjan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/gunjan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "494e3bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['marvel/Iron-Man.2.txt', 'marvel/Spider-Man.Far.From.Home.txt', 'marvel/Captain.Marvel.txt']\n",
      "\n",
      "Total number of movie scripts: 23\n"
     ]
    }
   ],
   "source": [
    "txt_files = glob.glob('marvel/*.txt')\n",
    "\n",
    "print(txt_files[:3], end='\\n\\n')\n",
    "print(\"Total number of movie scripts:\", len(txt_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a064667",
   "metadata": {},
   "outputs": [],
   "source": [
    "marvel_corpus = ''\n",
    "\n",
    "for file in txt_files:\n",
    "    with open(file, 'r', encoding=\"ISO-8859-1\") as f:\n",
    "        text = f.read()\n",
    "        marvel_corpus += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "775128db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text from the corpus:\n",
      "\n",
      " urned. we're adjourned for today.\n",
      "- okay. - you've been a delight.\n",
      "my bond is with the people.\n",
      "and i will serve this great nation at the pleasure of myself.\n",
      "if there's one thing i've proven\n",
      "it's that you can count on me to pleasure myself.\n",
      "wake up. daddy's home.\n",
      "welcome home, sir.\n",
      "congratulations on the opening ceremonies.\n",
      "they were such a success, as was your senate hearing.\n",
      "and may i say how refreshing it is\n",
      "to finally see you in a video with your clothing on, sir.\n",
      "you!\n",
      "i swear to god i'll dis\n"
     ]
    }
   ],
   "source": [
    "marvel_corpus = marvel_corpus.lower()\n",
    "print('Sample text from the corpus:\\n\\n', marvel_corpus[9500:10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be0119e-77db-4158-a4e4-4a71582478d4",
   "metadata": {},
   "source": [
    "## Cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bc77f0b-e0e6-493f-8679-6cc1ba028710",
   "metadata": {},
   "outputs": [],
   "source": [
    "Word = WordNetLemmatizer()\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcf73202-a5e4-40a4-9bfe-7a8128d0587c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to clean up everything: 0.04 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "text = marvel_corpus\n",
    "text=re.sub(r\"[^.A-Za-z]\",' ',text)\n",
    "sentence=text.split('.')\n",
    "tokens=[nltk.word_tokenize(words) for words in sentence]\n",
    "\n",
    "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f54d1254",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_filtered = []\n",
    "temp = []\n",
    "for sent in tokens:\n",
    "    temp = []\n",
    "    for word in sent:\n",
    "        word = Word.lemmatize(word)\n",
    "        if word not in stop_words:\n",
    "            temp.append(word)\n",
    "    tokens_filtered.append(temp)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c968b0c-dc28-4b9e-b5a2-b18527157f56",
   "metadata": {},
   "source": [
    "## bIGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e59a6b0b-9fcf-4c57-a157-1eb270752bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7630881b-3435-4d68-b7cb-434922e91a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 12:30:42: collecting all words and their counts\n",
      "INFO - 12:30:42: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 12:30:42: PROGRESS: at sentence #10000, processed 27569 words and 21158 word types\n",
      "INFO - 12:30:42: PROGRESS: at sentence #20000, processed 56951 words and 40162 word types\n",
      "INFO - 12:30:42: PROGRESS: at sentence #30000, processed 86987 words and 57782 word types\n",
      "INFO - 12:30:42: collected 66014 token types (unigram + bigrams) from a corpus of 103118 words and 36103 sentences\n",
      "INFO - 12:30:42: merged Phrases<66014 vocab, min_count=20, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 12:30:42: Phrases lifecycle event {'msg': 'built Phrases<66014 vocab, min_count=20, threshold=10.0, max_vocab_size=40000000> in 0.14s', 'datetime': '2022-06-25T12:30:42.224933', 'gensim': '4.2.0', 'python': '3.8.0 (default, Nov  6 2019, 21:49:08) \\n[GCC 7.3.0]', 'platform': 'Linux-5.13.0-51-generic-x86_64-with-glibc2.10', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# min_count (float, optional) â€“ Ignore all words and bigrams with total collected count lower than this value.\n",
    "phrases = Phrases(tokens_filtered, min_count=20, progress_per=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60f37690-8947-45ee-bec6-6e9ea9279ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 12:30:45: exporting phrases from Phrases<66014 vocab, min_count=20, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 12:30:45: FrozenPhrases lifecycle event {'msg': 'exported FrozenPhrases<13 phrases, min_count=20, threshold=10.0> from Phrases<66014 vocab, min_count=20, threshold=10.0, max_vocab_size=40000000> in 0.12s', 'datetime': '2022-06-25T12:30:45.435063', 'gensim': '4.2.0', 'python': '3.8.0 (default, Nov  6 2019, 21:49:08) \\n[GCC 7.3.0]', 'platform': 'Linux-5.13.0-51-generic-x86_64-with-glibc2.10', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d366405c-7db3-4307-8aaa-3b7cef2fc40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = bigram[tokens_filtered]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04860170-3a26-4811-96ae-e5bd6cf94ece",
   "metadata": {},
   "source": [
    "### Most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b6d494a-fc29-4097-a27f-0b439cfdc4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10005"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = defaultdict(int)\n",
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "09fd71e2-ca67-4c4a-b675-eab7668cd054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['know', 'wa', 'right', 'get', 'yeah', 'like', 'one', 'got', 'okay', 'go']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53060dfb-1cb4-4cb8-847d-7030bc235a1f",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a20e82db-e608-41cf-be30-38ec9beabb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f9a7d2e-ec64-4e72-b288-7c360b7dd820",
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "78366fde-9983-4360-b7e4-b4b56e901004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 12:35:47: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=100, alpha=0.025>', 'datetime': '2022-06-25T12:35:47.465703', 'gensim': '4.2.0', 'python': '3.8.0 (default, Nov  6 2019, 21:49:08) \\n[GCC 7.3.0]', 'platform': 'Linux-5.13.0-51-generic-x86_64-with-glibc2.10', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec(workers=cores-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bf8114ce-6a56-48a9-8e6e-2711407d0eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 12:35:50: collecting all words and their counts\n",
      "INFO - 12:35:50: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 12:35:50: PROGRESS: at sentence #10000, processed 27142 words, keeping 4910 word types\n",
      "INFO - 12:35:50: PROGRESS: at sentence #20000, processed 56184 words, keeping 7393 word types\n",
      "INFO - 12:35:50: PROGRESS: at sentence #30000, processed 85788 words, keeping 9269 word types\n",
      "INFO - 12:35:50: collected 10005 word types from a corpus of 101576 raw words and 36103 sentences\n",
      "INFO - 12:35:50: Creating a fresh vocabulary\n",
      "INFO - 12:35:50: Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 2833 unique words (28.32% of original 10005, drops 7172)', 'datetime': '2022-06-25T12:35:50.495412', 'gensim': '4.2.0', 'python': '3.8.0 (default, Nov  6 2019, 21:49:08) \\n[GCC 7.3.0]', 'platform': 'Linux-5.13.0-51-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "INFO - 12:35:50: Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 89803 word corpus (88.41% of original 101576, drops 11773)', 'datetime': '2022-06-25T12:35:50.496345', 'gensim': '4.2.0', 'python': '3.8.0 (default, Nov  6 2019, 21:49:08) \\n[GCC 7.3.0]', 'platform': 'Linux-5.13.0-51-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "INFO - 12:35:50: deleting the raw counts dictionary of 10005 items\n",
      "INFO - 12:35:50: sample=0.001 downsamples 54 most-common words\n",
      "INFO - 12:35:50: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 79256.13802244786 word corpus (88.3%% of prior 89803)', 'datetime': '2022-06-25T12:35:50.514031', 'gensim': '4.2.0', 'python': '3.8.0 (default, Nov  6 2019, 21:49:08) \\n[GCC 7.3.0]', 'platform': 'Linux-5.13.0-51-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "INFO - 12:35:50: estimated required memory for 2833 words and 100 dimensions: 3682900 bytes\n",
      "INFO - 12:35:50: resetting layer weights\n",
      "INFO - 12:35:50: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-06-25T12:35:50.548739', 'gensim': '4.2.0', 'python': '3.8.0 (default, Nov  6 2019, 21:49:08) \\n[GCC 7.3.0]', 'platform': 'Linux-5.13.0-51-generic-x86_64-with-glibc2.10', 'event': 'build_vocab'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.0 mins\n"
     ]
    }
   ],
   "source": [
    "# Building vocabulary table\n",
    "t = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11ff646-31d9-4dd5-9aca-b8f40ac64eac",
   "metadata": {},
   "source": [
    "### Training of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c7423a5c-59db-4151-b05e-af006cd0d9df",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 12:35:55: Word2Vec lifecycle event {'msg': 'training model with 11 workers on 2833 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-06-25T12:35:55.363403', 'gensim': '4.2.0', 'python': '3.8.0 (default, Nov  6 2019, 21:49:08) \\n[GCC 7.3.0]', 'platform': 'Linux-5.13.0-51-generic-x86_64-with-glibc2.10', 'event': 'train'}\n",
      "INFO - 12:35:55: EPOCH 0: training on 101576 raw words (79137 effective words) took 0.2s, 381511 effective words/s\n",
      "INFO - 12:35:55: EPOCH 1: training on 101576 raw words (79273 effective words) took 0.2s, 399413 effective words/s\n",
      "INFO - 12:35:55: EPOCH 2: training on 101576 raw words (79226 effective words) took 0.2s, 396452 effective words/s\n",
      "INFO - 12:35:56: EPOCH 3: training on 101576 raw words (79364 effective words) took 0.2s, 365748 effective words/s\n",
      "INFO - 12:35:56: EPOCH 4: training on 101576 raw words (79159 effective words) took 0.4s, 217270 effective words/s\n",
      "INFO - 12:35:56: EPOCH 5: training on 101576 raw words (79283 effective words) took 0.2s, 358885 effective words/s\n",
      "INFO - 12:35:57: EPOCH 6: training on 101576 raw words (79171 effective words) took 0.2s, 411030 effective words/s\n",
      "INFO - 12:35:57: EPOCH 7: training on 101576 raw words (79252 effective words) took 0.2s, 388120 effective words/s\n",
      "INFO - 12:35:57: EPOCH 8: training on 101576 raw words (79317 effective words) took 0.2s, 372355 effective words/s\n",
      "INFO - 12:35:57: EPOCH 9: training on 101576 raw words (79303 effective words) took 0.2s, 325213 effective words/s\n",
      "INFO - 12:35:57: Word2Vec lifecycle event {'msg': 'training on 1015760 raw words (792485 effective words) took 2.3s, 337328 effective words/s', 'datetime': '2022-06-25T12:35:57.715453', 'gensim': '4.2.0', 'python': '3.8.0 (default, Nov  6 2019, 21:49:08) \\n[GCC 7.3.0]', 'platform': 'Linux-5.13.0-51-generic-x86_64-with-glibc2.10', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.04 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=10, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c8a5d02a-e053-42c0-aca4-a244885d890a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 12:34:20: Word2Vec lifecycle event {'fname_or_handle': 'marvel_w2v.bin', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-06-25T12:34:20.175789', 'gensim': '4.2.0', 'python': '3.8.0 (default, Nov  6 2019, 21:49:08) \\n[GCC 7.3.0]', 'platform': 'Linux-5.13.0-51-generic-x86_64-with-glibc2.10', 'event': 'saving'}\n",
      "INFO - 12:34:20: not storing attribute cum_table\n",
      "INFO - 12:34:20: saved marvel_w2v.bin\n"
     ]
    }
   ],
   "source": [
    "w2v_model.save('marvel_w2v.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea063c6-1e9b-4c68-ac48-7ae2ddf0fa2d",
   "metadata": {},
   "source": [
    "## Exploring the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "06a5494b-945c-48c2-aea5-e1393e16b742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('group', 0.9990216493606567),\n",
       " ('created', 0.9989855885505676),\n",
       " ('company', 0.9989451766014099),\n",
       " ('vibranium', 0.998924195766449),\n",
       " ('drone', 0.998919665813446),\n",
       " ('finally', 0.9989016652107239),\n",
       " ('cross', 0.9988691806793213),\n",
       " ('enemy', 0.9988670945167542),\n",
       " ('pilot', 0.9988518357276917),\n",
       " ('fact', 0.9988443851470947)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the word is in the vocabulary before feeding in\n",
    "\n",
    "#Get most similar words\n",
    "w2v_model.wv.most_similar(positive=[\"hero\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bdd323c8-6065-4734-8606-64e48f828853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46241245"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity(\"batman\", 'joker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "23da6ccc-8596-459d-bbb0-a718ec9decb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hulk'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.doesnt_match(['batman', 'joker', 'hulk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "33ea0cf4-82b9-4803-a2d7-8098a3752cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bridge', 0.28366515040397644),\n",
       " ('kleenex', 0.28308799862861633),\n",
       " ('port', 0.27012956142425537)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"titanic\", \"james_cameron\"], negative=[\"christopher_nolan\"], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "62ddf782-efe0-4ffb-b1e0-eeddc178fe41",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/gunjan/Desktop/word2vec_project/Prepare_data_marvel.ipynb Cell 31'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gunjan/Desktop/word2vec_project/Prepare_data_marvel.ipynb#ch0000038?line=0'>1</a>\u001b[0m voc \u001b[39m=\u001b[39m w2v_model\u001b[39m.\u001b[39;49mwv\u001b[39m.\u001b[39;49mvocab\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gunjan/Desktop/word2vec_project/Prepare_data_marvel.ipynb#ch0000038?line=1'>2</a>\u001b[0m \u001b[39mlen\u001b[39m(voc)\n",
      "File \u001b[0;32m~/anaconda3/envs/w2v/lib/python3.8/site-packages/gensim/models/keyedvectors.py:735\u001b[0m, in \u001b[0;36mKeyedVectors.vocab\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    734\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvocab\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 735\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m    736\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe vocab attribute was removed from KeyedVector in Gensim 4.0.0.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    737\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUse KeyedVector\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms .key_to_index dict, .index_to_key list, and methods \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    738\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m.get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    739\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    740\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4"
     ]
    }
   ],
   "source": [
    "voc = w2v_model.wv.vocab\n",
    "len(voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaed3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "296e912957bd482cc6e88dcab6e634628d0861d6347ba5ff2b91c085c9501fc2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
